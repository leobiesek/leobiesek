# -*- coding: utf-8 -*-
"""Machine_Learning__Application_Dataset_Apartment_Price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_aJvRuc-8Pff4pMou32zahuaoi7YVbjg

**Importing Libraries**
"""

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.linear_model import LinearRegression
from sklearn import metrics

"""**Importing the database**"""

database = pd.read_excel('https://github.com/MCAGoncalves/dataset/blob/main/Dataset_Rossman.xlsx?raw=true')

"""**Database Information**"""

database.describe()
#database.head()
#database.info()
#database.columns()

"""**Data cleaning**"""

#database.isnull()
#database.isnull().sum()
#database.fillna(database.mean())
#database.dropna(inplace=True)

"""**Defining the dependent variable and the independent variables**"""

X = database.drop(['Price'], axis=1)
y = database['Price']

"""**Split data into training and testing**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=False, test_size=0.3)

"""**Forecast and Errors**"""

#Creating the models
models = [
    GradientBoostingRegressor(learning_rate=0.1, n_estimators=100),
    KNeighborsRegressor(n_neighbors=20),
    SVR(),
    DecisionTreeRegressor(random_state=0),
    LinearRegression()
]

predictions_list = []
MAE_list = []
MAPE_list = []
MSE_list = []
RMSE_list = []

for model in models:
#Training models
    model.fit(X_train, y_train)
#Forecast
    y_pred = model.predict(X_test)
    predictions_list.append(y_pred)
#Applying error metrics
    MAE = metrics.mean_absolute_error(y_test, y_pred)
    MAPE = metrics.mean_absolute_percentage_error(y_test, y_pred)
    MSE = metrics.mean_squared_error(y_test, y_pred)
    RMSE = np.sqrt(MSE)
    MAE_list.append(MAE)
    MAPE_list.append(MAPE)
    MSE_list.append(MSE)
    RMSE_list.append(RMSE)

# Creating the dataframe for forecasts
predictions_df = pd.DataFrame({
    'GB': predictions_list[0],
    'KNN': predictions_list[1],
    'SVM': predictions_list[2],
    'RF': predictions_list[3],
    'LR': predictions_list[4],
})
predictions_df = predictions_df.round(2)
print(predictions_df)

# Creating the dataframe for Errors
errors_df = pd.DataFrame({
    'MAE': MAE_list,
    'MAPE': MAPE_list,
    'MSE': MSE_list,
    'RMSE': RMSE_list
}, index=['Gradient Boosting', 'KNN', 'SVM', 'Random Forest', 'Linear Regression'])
errors_df = errors_df.round(2)
print(errors_df)

"""**Plot with the best forecasting technique**"""

# Finding the best model index
best_model_index = np.argmin(MAPE_list)

# Plot with the predictions of the best model
y_pred_best = predictions_list[best_model_index]
y_test_best = y_test.values

plt.figure(figsize=(10, 6))
plt.plot(y_pred_best, color='blue', linestyle='--', label='Prediction')
plt.plot(y_test_best, color='orange', label='Test Set')
plt.legend()
plt.xlabel('Index')
plt.ylabel('Price')
plt.title(f'Comparasion between the best model ({type(models[best_model_index]).__name__}) and Test Set ')
plt.show()

"""**Forecasting on a new predictor dataset**"""

# Loading the new data
#remembering database columns to identify predictor variables
#database.columns

X_real = [(25, 8, 2016, 6, 600, 0, 1),
          (30, 10, 2016, 8, 585, 1, 0)]

new_data_list = np.array(X_real)
new_data = new_data_list.reshape(-1, np.array(X_real).shape[1])


# Applying the trained model to the new dataset to get predictions
y_pred_new = models[best_model_index].predict(new_data)
y_pred_new
